# ì´ë¯¸ì§€ ë¶„ë¥˜(Image Classification) í”„ë¡œì íŠ¸ í…œí”Œë¦¿ (KR)
> (ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025-10-22 10:55)

## âœ… í•µì‹¬ íŠ¹ì§•
- **ë‘ ê°€ì§€ í•™ìŠµ ë°©ì‹** ì œê³µ
  1) `scratch_cnn.py` : **ì™„ì „ ìŠ¤í¬ë˜ì¹˜ CNN** (ì‘ì€ ë°ì´í„°ì…‹/ê³¼ì œìš©)
  2) `resnet_transfer.py` : **ResNet18 ì „ì´í•™ìŠµ** (ì‹¤ì „ ë² ì´ìŠ¤ë¼ì¸)
- **ImageFolder** í˜•ì‹ ë°ì´í„° ì‚¬ìš©: `data/train/class_x/...`, `data/val/class_y/...`
- **í•™ìŠµ/í‰ê°€/ì¶”ë¡ ** ìŠ¤í¬ë¦½íŠ¸ ë¶„ë¦¬: `train.py`, `evaluate.py`, `infer.py`
- **ì¬í˜„ì„±**: ì‹œë“œ ê³ ì •, ì²´í¬í¬ì¸íŠ¸ ì €ì¥, ë¡œê·¸ ì¶œë ¥
- **í¸ì˜ ìœ í‹¸**: ì¡°ê¸°ì¢…ë£Œ(EarlyStopping), í˜¼ë™í–‰ë ¬ ì €ì¥, best model ì €ì¥

## ğŸ“ í´ë” êµ¬ì¡°
```
image_classification_project_ko/
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ configs/
â”‚  â””â”€ default.yaml
â”œâ”€ src/
â”‚  â”œâ”€ models/
â”‚  â”‚  â”œâ”€ scratch_cnn.py
â”‚  â”‚  â””â”€ resnet_transfer.py
â”‚  â”œâ”€ utils.py
â”‚  â”œâ”€ train.py
â”‚  â”œâ”€ evaluate.py
â”‚  â””â”€ infer.py
â””â”€ scripts/
   â”œâ”€ train_scratch.sh
   â””â”€ train_transfer.sh
```

## ğŸ§© ë°ì´í„° ì¤€ë¹„ (ImageFolder)
```
data/
â”œâ”€ train/
â”‚  â”œâ”€ class_a/ xxx.jpg ...
â”‚  â””â”€ class_b/ yyy.jpg ...
â””â”€ val/
   â”œâ”€ class_a/ ...
   â””â”€ class_b/ ...
```
- í´ë˜ìŠ¤ ì´ë¦„ì´ **ë¼ë²¨**ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
- í…ŒìŠ¤íŠ¸ê°€ ë”°ë¡œ ìˆìœ¼ë©´ `--test_dir data/test`ë¡œ í‰ê°€/ì¶”ë¡  ì‹œ ì§€ì •.

## âš™ï¸ ì„¤ì¹˜
```
python -m venv .venv && source .venv/bin/activate  # (Windows) .venv\Scripts\activate
pip install -r requirements.txt
```

## ğŸš€ í•™ìŠµ
### 1) ìŠ¤í¬ë˜ì¹˜ CNN
```
python -m src.train --model scratch --train_dir data/train --val_dir data/val \
  --epochs 20 --batch_size 64 --lr 1e-3 --img_size 224
```

### 2) ResNet18 ì „ì´í•™ìŠµ
```
python -m src.train --model resnet18 --train_dir data/train --val_dir data/val \
  --epochs 10 --batch_size 64 --lr 3e-4 --img_size 224 --freeze_backbone true
```

## ğŸ“Š í‰ê°€
```
python -m src.evaluate --ckpt runs/best.pt --val_dir data/val --img_size 224
# (ì„ íƒ) --test_dir data/test
```

- `runs/metrics.json`ì— ì •ëŸ‰ ì§€í‘œ ì €ì¥, `runs/confusion_matrix.png` ì €ì¥.

## ğŸ” ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
```
python -m src.infer --ckpt runs/best.pt --image path/to/image.jpg --img_size 224
```

## ğŸ§ª ë¹ ë¥¸ ìƒ˜í”Œ ì‹¤í–‰(ë”ë¯¸)
ë”ë¯¸ í´ë” êµ¬ì¡°ë§Œ ìˆì–´ë„ ì»¤ë§¨ë“œ/ì—ëŸ¬ íë¦„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ í•™ìŠµì—ëŠ” ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.

## ğŸ§° íŒ
- ì‘ì€ ë°ì´í„°ì…‹: `scratch`ê°€ ì˜¤íˆë ¤ ê³¼ì í•©/ìˆ˜ë ´ì´ ë¹ ë¥¼ ìˆ˜ ìˆìŒ
- ì¼ë°˜ ë² ì´ìŠ¤ë¼ì¸: `resnet18` ê³ ì • â†’ `--freeze_backbone false`ë¡œ í’€ê³  ë¯¸ì„¸ íŠœë‹
- ë°ì´í„° ì¦ê°•: `train.py` ë‚´ë¶€ `get_transforms`ì—ì„œ ê°„ë‹¨íˆ ì¡°ì ˆ ê°€ëŠ¥  
  
---  
  
# ğŸ§  CNN ì´ë¯¸ì§€ ë¶„ë¥˜ ì½”ë“œ ìŠ¤ë‹ˆí«
> ë”¥ëŸ¬ë‹ ì½”ë”©í…ŒìŠ¤íŠ¸ë‚˜ ì‹¤ë¬´ í…ŒìŠ¤íŠ¸ì—ì„œ **ë°”ë¡œ ë³µë¶™ ê°€ëŠ¥í•œ í•µì‹¬ êµ¬ì¡° ìš”ì•½ì§‘**  
> ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025-10-22 11:29

---

## ğŸ“Œ ê¸°ë³¸ êµ¬ì¡°
CNN ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œëŠ” ëŒ€ë¶€ë¶„ ì•„ë˜ ìˆœì„œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

1. **ë°ì´í„°ì…‹ ì •ì˜ (Dataset / DataLoader)**
2. **ëª¨ë¸ ì •ì˜ (CNN êµ¬ì¡°)**
3. **ì†ì‹¤í•¨ìˆ˜ & ì˜µí‹°ë§ˆì´ì € ì •ì˜**
4. **í•™ìŠµ ë£¨í”„ (train / validation)**
5. **í‰ê°€ ë° ì˜ˆì¸¡**

---

## 1ï¸âƒ£ ë°ì´í„°ì…‹ & ë¡œë” ì„¤ì •
```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

train_tf = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])
])

test_tf = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])
])

train_ds = datasets.ImageFolder("data/train", transform=train_tf)
test_ds = datasets.ImageFolder("data/test", transform=test_tf)

train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)
test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False)

num_classes = len(train_ds.classes)
```

---

## 2ï¸âƒ£ CNN ëª¨ë¸ ê¸°ë³¸ êµ¬ì¡° (ê°€ë²¼ìš´ SmallCNN)
```python
import torch.nn as nn

class SmallCNN(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
        )
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1,1)),
            nn.Flatten(),
            nn.Linear(128, 128), nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.classifier(self.features(x))
```

âœ… **Tip:** `AdaptiveAvgPool2d(1,1)` ë•ë¶„ì— ì…ë ¥ í¬ê¸°ê°€ ë‹¬ë¼ë„ ë™ì‘.

---

## 3ï¸âƒ£ í•™ìŠµ ì¤€ë¹„
```python
import torch
import torch.nn as nn
import torch.optim as optim

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SmallCNN(num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)
```

---

## 4ï¸âƒ£ í•™ìŠµ ë£¨í”„ (Train + Validate)
```python
for epoch in range(10):
    model.train()
    train_loss, correct, total = 0, 0, 0
    for x, y in train_loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * x.size(0)
        pred = out.argmax(1)
        correct += (pred == y).sum().item()
        total += y.size(0)
    acc = correct / total
    print(f"[{{epoch+1}}] loss={{train_loss/total:.4f}} acc={{acc:.4f}}")
```

---

## 5ï¸âƒ£ í‰ê°€ & ì˜ˆì¸¡
```python
from sklearn.metrics import accuracy_score, classification_report

model.eval()
y_true, y_pred = [], []
with torch.no_grad():
    for x, y in test_loader:
        x = x.to(device)
        out = model(x)
        preds = out.argmax(1).cpu().tolist()
        y_pred += preds
        y_true += y.tolist()

print("Accuracy:", accuracy_score(y_true, y_pred))
print(classification_report(y_true, y_pred, target_names=train_ds.classes))
```

---

## 6ï¸âƒ£ ê°œì„ ìš© ìŠ¤ë‹ˆí« ëª¨ìŒ

### âœ… BatchNorm ì¶”ê°€
```python
nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU()
```

### âœ… Data Augmentation ë‹¤ì–‘í™”
```python
transforms.RandomRotation(10),
transforms.ColorJitter(brightness=0.2, contrast=0.2),
transforms.RandomErasing(),
```

### âœ… Scheduler / Early Stopping
```python
from torch.optim.lr_scheduler import CosineAnnealingLR
scheduler = CosineAnnealingLR(optimizer, T_max=10)

for epoch in range(10):
    # train loop ...
    scheduler.step()
```

### âœ… ëª¨ë¸ ì €ì¥ / ë¡œë“œ
```python
torch.save(model.state_dict(), "best.pt")
model.load_state_dict(torch.load("best.pt", map_location=device))
```

### âœ… ì˜ˆì¸¡ í™•ë¥  ë³´ê¸°
```python
import torch.nn.functional as F

with torch.no_grad():
    img = next(iter(test_loader))[0][0].unsqueeze(0).to(device)
    probs = F.softmax(model(img), dim=1)[0]
    for cls, p in zip(train_ds.classes, probs):
        print(f"{{cls}}: {{p.item():.3f}}")
```

---

## 7ï¸âƒ£ ë¹ ë¥¸ í…œí”Œë¦¿ (10ì¤„ ì»·)
```python
model = SmallCNN(num_classes).to(device)
opt = torch.optim.Adam(model.parameters(), lr=1e-3)
crit = nn.CrossEntropyLoss()
for e in range(10):
    for x, y in train_loader:
        x, y = x.to(device), y.to(device)
        opt.zero_grad()
        l = crit(model(x), y); l.backward(); opt.step()
```

---

## ğŸ§© ë©´ì ‘/ì‹œí—˜ì—ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” ì§ˆë¬¸
| ì§ˆë¬¸ | í•µì‹¬ ìš”ì•½ |
|------|-------------|
| CNNì—ì„œ **ì»¤ë„ í¬ê¸° 3**ì˜ ì˜ë¯¸ëŠ”? | ì…ë ¥ íŠ¹ì§•ì„ 3Ã—3 ì˜ì—­ ë‹¨ìœ„ë¡œ ë³´ëŠ” í•„í„° |
| **Padding=1**ì„ ì£¼ëŠ” ì´ìœ ëŠ”? | ì¶œë ¥ í¬ê¸°ë¥¼ ì…ë ¥ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ |
| **Pooling**ì„ í•˜ëŠ” ì´ìœ ëŠ”? | ê³µê°„ í¬ê¸° ê°ì†Œ, translation-invariance í™•ë³´ |
| **ReLU**ë¥¼ ì“°ëŠ” ì´ìœ ëŠ”? | ë¹„ì„ í˜•ì„± ë¶€ì—¬ + gradient vanishing ì™„í™” |
| **Dropout**ì€ ì–¸ì œ ì“°ë‚˜? | ê³¼ì í•© ë°©ì§€, Fully Connected ì¸µì— ì£¼ë¡œ ì‚¬ìš© |
| **CrossEntropyLoss**ëŠ” Softmaxë¥¼ í¬í•¨í•˜ë‚˜? | âœ… ë„¤, ë‚´ë¶€ì ìœ¼ë¡œ `log_softmax`ê°€ í¬í•¨ë¨ |
| **AdaptiveAvgPool2d(1,1)**ì˜ ì—­í• ì€? | ì…ë ¥ í¬ê¸°ì— ìƒê´€ì—†ì´ 1Ã—1ë¡œ ì „ì—­ ìš”ì•½ |

---

## ğŸ¯ í•œ ì¤„ ìš”ì•½
> â€œConv + ReLU + Pool ë°˜ë³µ â†’ ì „ì—­ìš”ì•½(GAP) â†’ Fully Connected â†’ Softmax(Class)â€  
> ì´ê²Œ ì´ë¯¸ì§€ ë¶„ë¥˜ CNNì˜ ê¸°ë³¸ ë¼ˆëŒ€ë‹¤! ğŸ’ª

---

### ğŸ“˜ ì¶”ì²œ ì—°ìŠµ ë¬¸ì œ (ì½”ë”©í…ŒìŠ¤íŠ¸ ì—°ìŠµìš©)
- [Dacon: ì‹ë¬¼ ì ì§ˆë³‘ ë¶„ë¥˜](https://dacon.io/competitions/official/235862)
- [Kaggle: CIFAR-10 Image Classification](https://www.kaggle.com/c/cifar-10)
- [AI Stage: Tiny Image Classification]()

---